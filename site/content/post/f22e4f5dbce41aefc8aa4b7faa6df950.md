---
layout: default
Lastmod: 2023-08-12T22:31:22.869126+00:00
date: 2023-08-12T22:31:21.971941+00:00
title: "人工智能能有多可怕？"
author: "方舟子"
tags: [人工智能,研发,灭绝,签名,人类，新语丝]
---

人工智能能有多可怕？

·方舟子·

一批研发人工智能的科学家、工程师、业界领袖联合发表声明，警告人们：人工智能有造成灭绝人类的风险。这个声明是放在网上征集签名的，签名的人数会越来越多，现在已有300多人签名。其中包括研发出ChatGPT的OpenAI公司老总、谷歌研发人工智能的DeepMind公司老总，以及两个因研究人工智能获得图灵奖（计算机科学领域的最高奖）的科学家。这个声明很简单，只有一句话：减轻人工智能可能带来的灭绝风险要成为全球优先做的事情，就像对待其他社会级别的风险，例如瘟疫大流行和核武器一样。为什么只有一句话呢？据组织签名的人说，因为这更容易有共识。

人工智能有可能灭绝人类并不是什么新的想法，很早以前就有了。几年前，谷歌研发的AlphaGo打败了李世石，当时就有人说，人工智能再这么搞下去，会变得智力非常高超，会因此把人类消灭了。我当时就说这是危言耸听，是科幻小说、科幻电影看多了。

有人可能会说，你不是搞人工智能的专家，在这方面有什么发言权？难道你比那三百多个研发人工智能的专家、权威对这个问题更懂吗？

人工智能会不会毁灭人类不是一个技术问题，而是一个哲学问题，不需要是人工智能领域的专家也可以对这个问题进行讨论、发表见解。今年三月份，也有一千多人联合发表了一篇声明警告人们，人工智能很危险，呼吁研发人工智能的人暂时停止研发6个月。这一千多人并不都是搞人工智能的，实际上绝大部分不是搞人工智能的，他们也签名了。例如马斯克本身并不搞人工智能，未必懂人工智能，但也签名了。可见对这个问题，不是该领域的专家、权威也有发言权。

而且，关于人工智能会不会灭绝人类，在人工智能领域并没有形成共识。虽然签名的人数有三百多，听上去好像很多，但人工智能是一个非常热门的领域，研发的人非常多，专家、权威也非常多，这三百多人只是其中的一小部分而已。那些研发人工智能的公司并没有都签名，例如脸书下面研发人工智能的公司就没有签名。因研究人工智能获得图灵奖的科学家也并没有都签名。所以这并不是人工智能业界的共识。

这些研发人工智能的人出来警告人们，人工智能有灭绝人类的风险，让人觉得很蹊跷，动机很可疑。他们本身就在研发人工智能，而且是这个领域的领军人物，为什么却要人们警惕人工智能的危险，甚至是灭绝人类这么吓人的危险？他们为什么还要明知故犯去研究一个有可能灭绝人类的、如此恐怖的技术呢？这一方面是要显得自己很自律，站在道德高位；另一方面是希望政府把这个领域管起来。政府的管理对这些领先的公司、人物影响不会太大，对那些黑马影响更大，而这些领先公司、人物就可以一直保持领先的地位。社交媒体领域最大的公司脸书一直在呼吁美国政府把社交媒体管起来，也是同样的理由，一方面显得自己很高尚，另一方面，这个领域真的被管起来，会对别的社交媒体造成更大的负面影响，对已经领先、有着优势地位的公司影响不会很大。

所以，这么呼吁的人其实是言不由衷的，是别有用心的。如果他们真的认为人工智能这么可怕，那么在政府管理之前，他们就应该首先自律，暂停人工智能的研究，就像三月份那1000多个人发的声明里说的，暂停研究人工智能6个月。但三月份发声明的1000多人中也有一部分是研发人工智能的，或者本身不研发但投资人工智能的。比如马斯克，本身不懂人工智能、不研发人工智能，但他投资了至少两家人工智能公司。但是他虽然参与签名呼吁暂停研究6个月，自己投资的公司却没有暂停。这些研发、投资人工智能的，继续在研发、投资人工智能，丝毫没有停下来的迹象，反而竞争更加激烈。发这样的声明是不是显得很虚伪？

人工智能是一项技术，跟其他技术一样，如果被滥用，当然会带来一定的社会问题，造成一定的风险。目前面临着的最大问题是人工智能被用于制造、散布虚假信息。ChatGPT现在非常火，很多人都在使用，但也有很多人不知道ChatGPT提供的信息并不都是准确的，经常会胡编乱造、以假乱真。最近在美国就有一个例子。一个律师使用ChatGPT写答辩词，交给法庭后被法官发现他引用的6个案例都是假的，是ChatGPT胡编出来的。而且，现在用人工智能来制造假照片、假视频已经达到足以乱真的地步，人们识别起来非常麻烦。这个问题会变得越来越严重，是应该重视的。

其次，人工智能的发展会导致一些行业过时，会有相当多的人要失业、转行。这并不是一个新的问题。很多技术的发明、发展都会带来同样的问题，都会导致一些行业消失，很多人失业、转行，人工智能并不是一个例外。还有，人工智能以后有可能被用于帮助研发武器，比如生物武器、化学武器，导致这些武器杀伤力非常强。这是不是说明人工智能会毁灭人类呢？人工智能在这方面只是一个工具而已。研发生物武器、化学武器还要用到别的技术，那么是不是说明这些技术也会导致人类灭绝呢？其实，研发这种能导致人类灭绝的大规模杀伤武器，都是邪恶政权干的，再怎样立法、管理，对他们来说都是不起作用的。而且，早就有灭绝人类的技术了，核武器技术已经有了，没有必要等到人工智能达到多高的程度才会导致人类灭绝。

对于人工智能有可能带来的社会问题，当然要正视，并不是说不存在。我们反对的是危言耸听，把它说得特别严重。这让我想起上世纪七十年代，基因工程刚刚发明，也有一些生物学家把基因工程想象得特别可怕，要求业界自律，呼吁政府管理，结果还真把一些官员吓住了。欧洲对基因工程研究管得非常严，美国则管得很松。结果导致在生物技术领域，美国大大领先欧洲。现在回头来看，基因工程技术已经发展到了相当高的程度，毁灭人类了吗？现在还有哪一个生物学家认为基因工程搞不好就会毁灭人类呢？几十年前的那种担忧，是不是很可笑呢？

2023.05.31录制

2023.07.26整理

(XYS20230805)

