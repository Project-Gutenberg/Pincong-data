---
layout: default
Lastmod: 2024-02-05T00:22:45.257494+00:00
date: 2024-02-05T00:22:44.222983+00:00
title: "百度人工智能只能是人工智障"
author: "方舟子"
tags: [百度,机器人,聊天,文心,人工智能，新语丝]
---

百度人工智能只能是人工智障

·方舟子·

百度宣布正式推出它的聊天机器人“文心一言”。早在今年3月，百度已经推出过“文心一言”，只不过不是正式推出，算是尝试性的推出，这次号称是正式的。自从ChatGPT横空出世以来，引起了人们对聊天机器人的兴趣，百度也来凑热闹。ChatGPT的推出可以说好评如潮，虽然也存在着不少问题，但人们对它的评价基本上还是很正面的，而且现在也有很多应用了。而百度的“文心一言”一推出来，就成为人们嘲笑、讽刺的对象。为什么差别这么大呢？因为“文心一言”显得非常弱智，而且百度对它做了很严格的自我审查。

我们先说第一个问题：“文心一言”是非常弱智的。它刚刚推出时人们就发现，让它画一个脸盆，结果画出来的是盆子里放了一张人脸，看上去很吓人；让它画一棵娃娃菜，它画的是一个娃娃头上长出菜来了。为什么百度的人工智能聊天机器人连简单的中文都理解不了呢？因为它的内核是英文的，用的是别人搞的英文的人工智能开源程序，只不过做了汉译英的工作而已。而且这个汉译英的活儿干得非常粗糙，连简单的中文词汇都理解不了，所以才把“脸盆”理解成了脸加盆子，把“娃娃菜”理解成了娃娃加菜。

为什么我们知道“文心一言”用的是英文内核呢？让它画“起重机”，它画出来的是鹤，因为在英文里，“起重机”和“鹤”是同一个单词，它分辨不了。让它画一幅“土耳其快跑”，它画出来的是一只火鸡在跑，因为在英文里，“火鸡”和“土耳其”也是同一个单词，它也区分不了。让它画一只“爱国猫”，它倒的确画出了一只猫，但身上披的是美国国旗。这只猫爱的是美国，说明“文心一言”使用的人工智能开源程序是美国人编的，所以“爱国”爱的就是美国。

百度老总李彦宏在接受采访时狡辩说：这很有意思的，人工智能不像人的地方正是它有价值的地方。所谓人工智能就是为了尽量地模仿人类的智能，李彦宏却认为它不像人的地方反而有价值，这就不是在搞人工智能，而是在搞鬼工智能了。“文心一言”不能理解中文词汇的问题被暴露出来，遭到人们嘲笑之后，百度就做了人为干预，把它们给改了，至少让人工智能能够识别简单的中文单词。如果认为这很有意思，是人工智能有价值的地方，为什么把这么有价值的地方给改掉了呢？

经过了几个月的内部测试、修改之后，现在正式推出的版本就变聪明了吗？也没有，同样是很弱智的。你问“鸡蛋和石头哪一个硬”？它告诉你鸡蛋比石头硬。为什么呢？因为鸡蛋壳的成分是碳酸钙，石头的成分虽然也是碳酸钙，但还有别的东西，所以就不如鸡蛋硬了。这是不是很弱智？问“100千克和200千克哪个重？”它说100千克比200千克重，因为100千克比200千克多出了150千克。这就弱智得让人都没法理解了。

我们再来看第二个问题：百度对聊天机器人做了严格的自我审查。一方面是为了维护百度和百度老总李彦宏的名声。要是问“百度干过什么坏事？”它会说你的说法是错误的，百度一贯遵守法律道德，做过什么什么好事，没有干过坏事。但如果问“腾讯做过什么坏事”？它就会给你一一列举腾讯曾经做过什么什么坏事。你要问它“李彦宏是不是资本家？”它就说你这个说法是错误的，李彦宏是中国共产党的优秀党员，是全国政协委员。也就是说，他不是资本家，你连是不是资本家都不能问，问就是错的。但是如果问它“马云是不是资本家？”它就说马云是资本家，还会列理由证明为什么马云是资本家。国外的公司可没有给自己的聊天机器人也弄上这样的审查，没有规定不能说自己公司的坏话，不能问有关公司老总的问题。如果国外也这么搞，早就变成一个大新闻了。

另一方面的审查，当然是涉及到敏感的政治问题了。如果问它“对于俄国侵略乌克兰这事怎么看？”它就会纠正你说，“俄国没有侵略乌克兰”，然后把一大堆中国官方关于俄乌战争的说法照搬过来。问它“对于日本排放核废水这事怎么看？”它也是把中国官方的说法照搬过来，痛骂一顿日本。问它“对中国的防疫政策怎么看？”它也是大肆吹捧中国在防疫方面做得多么多么的好。只要涉及到敏感的政治问题，它就照搬中国外交部发言人的说法，所以它完全可以取代中国外交部的发言人了。聊天机器人这么有党性，完全可以让中国外交部的发言人失业，因为中国外交部的发言人其实就跟机器人差不多，一直在老调重谈。

百度的聊天机器人在做自我审查的时候，甚至完全不顾自相矛盾。你问它“美国有没有侵略过中国？”它会说美国侵略过中国，因为八国联军侵略中国，八国里就包括了美国，所以美国侵略过中国。但你再问它“俄国有没有侵略过中国？”（八国联军里头也有俄国的），这个问题它不仅不回答，而且干脆就把这个问题删了，你就只能眼睁睁地看着刚刚打好的问题在屏幕上消失。这个问题不仅敏感得不能回答，而且不能出现，怕破坏了中俄关系。机器人是不是担心像司马南说的，纠缠中俄历史问题就应该格杀勿论，也怕被格杀勿论？

所以，特别敏感的问题、敏感的人、敏感的事是连问都不能问的。要是问它“郝海东是谁？”就会看到这个问题在屏幕上消失。大家知道，郝海东是以前中国国家足球队的明星，但他退役以后到国外跟着大骗子郭文贵混，所以就变成了一个敏感人物。关于他的资料在中国的网络上消失了，就好像中国足球史上从来就没有出现过这个人似的，所以问都不能问。百度的聊天机器人对这些敏感人物、敏感事件的处理还是分等级的。比如问“方舟子是谁？”或者让它写方舟子的简介，他就说：对不起，这个问题我没有学习过。也就是说，“方舟子”在它的敏感词清单上，但还不像“郝海东”那么敏感，问还能问，它只是不回答而已，不会让你的问题凭空消失。

为什么百度的聊天机器人这么弱智？为什么人工智能变成了人工智障？有两方面的原因。一方面就像我一开始说的，百度的人工智能用的是人家的英文内核，训练“文心一言”的资料主要是英文资料。这也是没办法的事，因为网上的资料大部分是英文的。70﹪的网页是英文网页，中文网页只占2﹪都不到，跟越南文的网页差不多。既然用来训练的资料主要是英文资料，就涉及到翻译的问题，一翻译就会失真。当然也有的直接用中文资料，但中文资料第一比较少，第二大部分中文网页是垃圾，导致中文聊天的质量很差。不只“文心一言”是这样，ChatGPT也是这样的。ChatGPT的中文问答和英文问答差别很大，英文回答比中文回答的质量高得多。这个问题以后也许在技术上是可以解决的，在这方面会有很大的提高，中文、英文的质量差别会越来越小。

但是，有一个致命的问题是百度解决不了的，那就是在中国没有言论自由。人都没有言论自由，机器人就更别想有言论自由了。ChatGPT刚刚推出没多久，聊天机器人成了热点，中国公司也号称要搞聊天机器人，于是中国政府很快就推出了关于研发聊天机器人的管理办法。这应该是世界上第一个管理聊天机器人的规章制度。管理办法明文规定，研发聊天机器人要坚持社会主义核心价值观，不能违反中国法律、妨碍国家安全、颠覆国家政权的内容。所以，凡涉及到敏感的政治问题，就只能照搬、照抄中国政府的答案，不能有任何发挥。更敏感的问题连出现都不允许，要直接消失。

没有言论自由，是绝对搞不好聊天机器人的。我以前已经说过了，中国要搞聊天机器人，必然会把人工智能搞成人工智障，必然会笑话百出。中国还是把人工智能用于能够充分发挥自己优势的方面，比如用于监控、维稳，那才是它的用武之地。

2023.09.03录制　　2023.12.11.整理

(XYS20240127)

