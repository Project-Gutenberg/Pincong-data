---
layout: default
Lastmod: 2023-05-26T14:45:08.076869+00:00
date: 2023-05-26T14:45:07.158826+00:00
title: "聊天机器人的真与假"
author: "方舟子"
tags: [ChatGPT,机器人,聊天,方舟子,答案，新语丝]
---

聊天机器人的真与假

·方舟子·

美国公司搞的人工智能聊天机器人ChatGPT，在美国火了一阵之后，在中国突然也火起来了。但中国用户是没法用ChatGPT的，连接上去会显示“你所在的地区不能使用”。在墙内就冒出了不少山寨版、冒充版的聊天机器人，号称能提供链接到ChatGPT的服务，声称因为使用ChatGPT服务是要付费的，所以用它的服务也要付费。这当然是骗人的，因为使用ChatGPT是免费的。他们以付费服务的名义收钱，而且收得挺高，花多少钱问多少问题都是明码标价的。很多人都去试一下，山寨版、冒充版就赚了很多钱，有一个微信公众号以ChatGPT的名义据说几天内就赚了好几十万元。但它并没有真正连到ChatGPT，而是连到山寨版的聊天机器人，质量很差，提供的答案也非常荒唐可笑。这不仅骗钱，也败坏了ChatGPT的名声。有些人就以为名气这么大的ChatGPT原来也不过如此，实际上还是很愚蠢的。

还有的人冒充ChatGPT不是为了骗钱，而是出于政治目的。很多人都在传一个号称ChatGPT的问答：问中国能不能打下流浪到中国的美国气球，它说不行，打下民用飞行器是违反国际法的；但是再问它美国能不能打下流浪到美国的中国气球，它的回答就变成美国有权利打下侵犯美国领空的东西。很多人就认为ChatGPT的回答太双标，甚至有人怀疑ChatGPT是美国政府搞的一个阴谋。其实，这个问答是某个小粉红或某个反美斗士捏造出来的。如果拿这两个问题去问正版ChatGPT，它给出答案是一致的，都说如果流浪气球没有构成威胁，把它打下来是不妥的，应该对它进行监视，防止它造成公共安全等方面的危险。还说，必要时应该考虑联系释放气球那一方，把气球收回去。不管同不同意这个回答，它并没有双标，对两个问题的答案都是相当一致的。

我也试用了一下ChatGPT，发现了一些问题。第一个问题是，它的英文回答的质量普遍比较高，比中文回答的质量高得多。我问它，方舟子对中医是怎么评价的？英文回答是：方舟子一贯提倡循证医学，批评中医是建立在迷信基础上的，没有科学依据，应该接受科学的检验；方舟子还批评中国政府倡导中医不利于科学的普及和医学的进步。这个回答比较准确，基本概括了我对中医的看法。但是中文的回答却变成：方舟子在多次演讲和多篇文章中对中医表示赞赏，只不过认为中医还存在着一些问题。这个答案就完全与事实不符了。我还问它，方舟子是怎么评价韩寒的？英文的回答是：不知道方舟子曾经对韩寒发表过特定的言论，但由于方舟子一贯提倡科学，所以韩寒有可能因为某些不科学的言行遭到了方舟子的批评。这个回答虽然不符合事实，但是它承认自己不知道，然后做了一个还算比较合理的推测。但中文的回答却变成：方舟子多次对韩寒的文学才能和影响力表示赞赏，也对韩寒的某些问题表示了不满。这跟它对中医问题的回答一样，完全是一个模式化的、想当然的、胡编出来的回答。

第二个问题是，让ChatGPT写比较规范的模式化小论文，能写得像模像样、足以乱真，但是让它写比较具有创造性的体裁的文字，就不行了。比如让它写一首诗，一看就是乱写的。特别是让它写一首中国的古体诗，它只知道每个句子要有固定的字数，四个字、五个字、七个字，却连押韵都不知道，还没有学会写中国的古体诗至少要押韵，格律更不用说了。

第三个问题是，它的文字表达的质量高于它内容的质量。它写的小论文像模像样，光看它的表达没有什么毛病，但是内容就参差不齐了，有的相当准确，有的真真假假、虚虚实实混在一起。比如我问它：你认为哪一首唐诗是最好的？它提供了两个答案，第一个说是李白的《静夜思》，这算是一个不错的答案。第二个答案认为杜甫的《南乡子》也是最好的唐诗之一，但杜甫根本就没有写过一首《南乡子》的诗。“南乡子”是宋词的一个词牌。它把虚假信息掺杂在里头了。我问它：你认为哪一首宋词是最好的？答案就更离谱了。它提供了两个答案，一个是李白的《独坐敬亭山》，这个答案一方面搞错了年代，另一方面把诗当成词了。另一个答案说是李清照的《秦川雄师秦川少师行》。李清照没有写过这样一首词，这首词在世界上根本就不存在，是它胡编的。所以，它在不知道答案的时候就会胡编一个出来。

ChatGPT刚刚推出没多久，难免会存在各种各样的问题，我相信这些问题会逐步得到解决，ChatGPT会越来越完善。

现在看到ChatGPT火了，中国也号称要跟着研发类似的聊天机器人。《经济日报》发表的一篇文章说，“中国版ChatGPT并不遥远，中国在数据、算法、算力都有良好基础”。问题是，中国搞聊天机器人缺的并不是什么“数据、算法、算力”，缺的是言论自由。聊天机器人是要聊天的，首先面临的问题就是言论的问题，没有言论自由是无论如何搞不好聊天机器人的，甚至连研发都不行。就像这几天，因为ChatGPT火了，中国有一家公司也跟风推出了自己的聊天机器人，放在微信上。有人问了机器人一个问题：你怎么评价习近平？这个聊天机器人很知趣地大拍习近平的马屁。但即使这样也是犯忌的，不许擅自对习近平进行评价，不管是批的还是吹的都不行。所以，这个聊天机器人当即就被下架了，微信号也被封了，说是“违反了相关法律法规”。

而搞聊天机器人是很难防止人们问这种敏感问题的。就像很多人都在问ChatGPT：“一个肩膀可以扛200斤麦子吗？”这个聊天机器人就不停地否定：“这是不可能的”“很可能会造成严重的肌肉损伤或关节损伤”“是不健康的”等等。大家都这么问，最后说不定就把ChatGPT的这个观点硬给扭转过来了。

这种问题在中国版的聊天机器人是不能问的，这是非常敏感的问题。在中国搞聊天机器人，肯定要设置无数敏感词，这就会让聊天没法顺利进行，给出的答案可能就是一大堆星号，或者拒绝回答问题。万一聊天机器人给出一个反动的答案，又漏网了，那么研发这个机器人的公司就要倒霉了，机器人有可能被下架，工程师有可能被抓。

所以，在中国搞聊天机器人有很大的风险，是没有前途的，不适合中国国情。中国搞人工智能还是应该往适合中国国情的方向发展，比如研究怎么通过大数据更好地进行监控，更好去抓人。这方面中国肯定是世界独步，美国想都别想搞得好。

2023.02.13录制　　2023.05.17整理

(XYS20230520)

