---
layout: default
Lastmod: 2020-06-29T06:41:34.531459+00:00
date: 2020-06-29T06:41:34.530933+00:00
title: "​深度学习先驱Yann LeCun被骂退推特：你们都很懂，从此我不说话了"
author: "Synced"
tags: [偏见,机器学习,推特,算法,CVPR]
---

机器之心报道

**作者：泽南、蛋酱**  

> 在长达两周的「骂战」之后，图灵奖得主、Facebook 首席 AI 科学家 Yann Lecun 宣布，自己将退出推特。

  

「**我请求社交网络上的所有人不要再互相攻击了**，特别是对于 Timnit Gebru 的攻击，以及对于我之前一些言论的攻击。」Yann LeCun 刚刚在推特上发出了这样的呼吁。「**无论是口头还是其他方式的冲突，都只能获得伤害和相反的结果。我反对一切形式的歧视。**这里有一篇关于我核心价值观的文章。」

  

「这是我在推特上最后一篇有内容的帖子，大家再见。」

  

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEu90Ixztf6R1MiaWHN0P2AL7pro1yzLiboadMUEGh6tL5DvOAWfkxey0jcs4XozgYx5vA5mOS3hVw/640%3Fwx_fmt%3Dpng)

  

看起来 2018 年图灵奖得主、人工智能领军人物 Yann LeCun 已经下定决心想对长达两周的激烈讨论画上句号。而这场闹得沸沸扬扬的骂战，起因正是被指「严重种族歧视」的 PULSE 算法。

  

这一工作由杜克大学推出，其人工智能算法可以将模糊的照片秒变清晰，效果极佳。这项研究的论文已在 CVPR 2020 上发表（论文《[PULSE：Self-Supervised Photo Upsampling via Latent Space Exploration of Generative Models](http://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650790518&idx=1&sn=9c945d61631f7e42d85c64de03a59f93&chksm=871a1e08b06d971e7fc961d01893e152ae7f8f7f5da99d12f25d5ca049d632fc45f77ea8eb8d&scene=21#wechat_redirect)》）。

  

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEu90Ixztf6R1MiaWHN0P2ADASoRLEq0icWoLSgFy6HjibDgia8QJCX4QL0gpkJfMUa4bwbclib3wWCYw/640%3Fwx_fmt%3Dpng)

  

PULSE 在 CVPR 大会期间引来了人们的关注，进而引发了 AI 社区的广泛争议。首先，这种方法所产出的图像清晰度更高，细节也更加丰富：PULSE 能够在几秒内将一张 16×16 像素的图片提升至 1024×1024 分辨率，提升高达 4096 倍。目前该算法仅针对人脸照片，算法生成的照片清晰到可以呈现出人脸上的毛孔、皱纹甚至一缕头发。

  

但本质上看，PULSE 并不是在消除马赛克，而是「生成」了看上去真实却并不存在的人脸。超分辨率算法一直是计算机科学的热门研究领域，以往科学家们提出的还原方法是在低分辨率图片中添加像素点。但 PULSE 使用 GAN 的思路，先利用深度学习算法生成一些高清图片，再降低它们的分辨率，并与模糊的原图对比，从中找出匹配程度最高、最接近原图的高清图像随后输出。

  

问题就出在这里，有网友试用了 PULSE 之后，发现美国前总统奥巴马的高糊照片经过去码处理以后，生成的是一张「白人面孔」：

  

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEu90Ixztf6R1MiaWHN0P2AyBiaotqicWRTfkicNBWoN4xic2aiczfIBdrLMxp6PFdj32fjCTjiagVAttUg/640%3Fwx_fmt%3Dpng)

  

有网友质疑该方法生成结果存在偏见，对此项目作者也给出了回应，表示这一偏见很可能来自于 StyleGAN 的训练数据集，可能还有其他未知因素。

  

「我们意识到偏见是机器学习和计算机视觉领域的重要问题，并就此问题联系了 StyleGAN 和 FFHQ 数据集的创建者。我们希望这能够促进不具备此类偏见行为的方法的诞生。」

  

但这件事还没完，鉴于美国目前 BLM 的舆论环境，人们很快就开始深入讨论机器学习研究结果缺乏多样性的问题。在这其中，种族偏见和性别偏见的问题一直存在，迄今为止却没人给出一个好的解决办法。 

  

也就在这个时候，Yann LeCun 发布了一条推特，来解释为什么 PULSE 会出现这样的偏见。

  

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEu90Ixztf6R1MiaWHN0P2A0OEURlP06zYtJFJ7FgmNhEJqmagVXz1604uRAgXaLrDD5jxyKS1LQQ/640%3Fwx_fmt%3Dpng)

  

「**机器学习系统的偏差是因为数据的偏差**。这一人脸上采样系统其结果倾向于白人是因为神经网络是在 FlickFaceHQ 上预训练的，其中的大部分图片基本是白人照片，」Yann LeCun 说道。「如果这一系统用塞内加尔的数据集训练，那肯定所有结果看起来都像非洲人。」  

  

Yann LeCun 的说法本身没有错，但可能是因为过于直白了，一下子让大量 AI 从业者和研究人员炸了锅。LeCun 希望将人们的注意力引向数据集的偏差，但推特网友不买帐，并指责他**「用这种陈旧的理由来掩盖问题本质」**。

  

之后，Yann LeCun 又在多条推文来解释自己关于偏见的立场，但仿佛已经没有用了。

  

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEu90Ixztf6R1MiaWHN0P2AKl56oiapw0hctKFHBHCnwz3H9RveGr2m6DCSTjzofHiae2E043PTlptA/640%3Fwx_fmt%3Dpng)

  

「与学术论文相比，这种偏见在已经部署的产品中产生的后果会更加可怕。」这句话的含义被解读为「不必为此特例而过分担心」，引发了诸多同行的质疑。  

  

斯坦福 AI Lab 成员、Google AI 科学家 Timnit Gebru（她是一名非洲裔美国人），对 LeCun 的言论表示「失望」。

  

Yann LeCun 甚至在 Timnit Gebru 的推特评论区连写 17 条回复：

  

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEu90Ixztf6R1MiaWHN0P2AWEXASoXiacibXqxiafVFGYptkzIwxpUZ8HPY2Qof0c7pAzw1ozkQwx1Xg/640%3Fwx_fmt%3Dpng)

  

当然，需要讨论的也不只是机器学习中的偏见问题：

  

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEu90Ixztf6R1MiaWHN0P2AianNfzghHCnEITwDicicR6E1PJzJ44Nwia41f0oapqZZib2IdTZP2huniarw/640%3Fwx_fmt%3Dpng)

  

「同样需要避免的是在对话中产生恶意，它只会激起情绪，伤害到所有人，掩盖实际问题，推迟解决方案的出现。」

  

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEu90Ixztf6R1MiaWHN0P2ABibdib8Z8I8d0HE4vveSbIWMmNRjaLLPN1YWicTAHYFG7gry6wVXbhPjQ/640%3Fwx_fmt%3Dpng)

  

从事数据科学领域超过十年的 Luca Massaron 认为，尽管从技术角度来看 Yann LeCun 是完全正确的，但看看这种观点被抛出之后公众的反应，你就会知道谈论它是多么的敏感。

  

「人们总是害怕自己会被不公平的规则控制，进而无条件地，有时甚至毫无理由地惧怕 AI 剥夺人们的自由，而不仅仅是工作，」Luca Massaron 说道。「我个人并不担心 Face Depixelizer 这类研究，我所害怕的是在应用之后，我们无法识别和挑战偏见。」

  

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEu90Ixztf6R1MiaWHN0P2AUpoyTlXzlLPagic7KLstHicI802et2FOArc7iaEr5baQuZUvlk8rqWyyA/640%3Fwx_fmt%3Dpng)

  

如今，越来越多的机器学习自动化技术正在进入我们的生活，立法者在这里扮演的角色非常重要。在欧盟国家，为了确保数据使用的透明度和责任，GDPR 条例要求互联网公司保证算法的可解释性，以及用户对于自身数据的控制力。

  

如果我们希望 AI 能够朝着正确的方向发展，我们需要追求的或许不是无偏见，而是透明度。Luca 认为，如果算法是有偏见的，我们可以挑战它的推断结果并解决问题。但如果算法的推理机制不可知，或许其中还隐藏着更大的问题。

  

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEu90Ixztf6R1MiaWHN0P2AX4sR6tGnF8x8PtvRAhVbNtHCxVbgAQck1orhson1ZEqGlTANicbEhxA/640%3Fwx_fmt%3Dpng)

  

不可否认的是，人类社会存在着各种偏见，但因此而认为机器倾向于更「流行」的答案是理所应当的，或许不是一个正确的观点。

  

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEu90Ixztf6R1MiaWHN0P2AtSly2ZFGLm7SiaZ2RaQAOacdiaiaCwTIWp3gFYnZySMLDnzhb10t4Cg5w/640%3Fwx_fmt%3Dpng)

_人们对于 PULSE 的讨论，以及 LeCun 的攻击，有很多已脱离了 LeCun 的本意。  
_

  

作为这场争议的起因，杜克大学的研究者们已在 PULSE 网站中表示将会修正有关偏见的问题。目前论文中已经增加了一个新的部分，并附加了可以解决偏差的模型卡。

  

为了达成没有偏见的目标，我们必须让整个人工智能社区行动起来。但在有关技术的讨论之中让技术大牛心灰意冷，是大多数人都不想看到的结果。Yann LeCun 此前一直以直言不讳著称，他在社交网络上经常会对热门的深度学习研究发表评论，也可以直面其他人工智能著名研究者的批评。

  

机器学习模型中的偏见可能会使得推理的专业性受到侵害，导致大量业务遭受影响却不为人所知。我们还没有解决这个问题一劳永逸的方法。

  

_参考内容：_

_https://analyticsindiamag.com/yann-lecun-machine-learning-bias-debate/_

  

  

机器之心 CVPR 2020 线上论文系列分享已经进行了九期。在最新一期的分享中，我们邀请到了 CVPR 2020 最佳论文的一作吴尚哲来为我们分享这篇论文的解决方案及亮点。

  

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/KmXPKA19gWicEu90Ixztf6R1MiaWHN0P2Ag1tWrgEJTuT7oCBS0g6ov8u18FI3oicqtYq8Kpksp4C4ibdGDeOsT9vA/640%3Fwx_fmt%3Dpng)

文章已于修改

