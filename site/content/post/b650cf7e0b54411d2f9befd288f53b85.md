---
layout: default
Lastmod: 2025-09-06T23:58:34.809752+00:00
date: 2025-09-06T23:58:34.809140+00:00
title: "GPT-4o 见 AV 女优的次数比「您好」还多 2.6 倍，AI 正在被中文互联网疯狂污染？"
author: "发现明日产品的"
tags: [AI,词元,污染,GPT,模型]
---

原创 发现明日产品的 [APPSO](javascript:void(0);)

好家伙，我直呼好家伙。

号称「赛博白月光」的 GPT-4o，在它的知识体系里，对日本女优「波多野结衣」的熟悉程度，竟然比中文日常问候语「您好」还要高出 2.6 倍。

是不是瞬间就下头了？

这可不是我瞎编的。一篇来自清华、蚂蚁和南洋理工的最新研究直接揭了老底：我们天天在用的大语言模型，有一个算一个，都存在不同程度的数据污染。

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9jY1FQDESwfzQIcUWW1fbkQf3R8LP2pKaXeWJaXR87vVdmL3dicYFSXQ/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

论文：从模型 Token 列表推测大语言模型的中文训练数据污染（🔗 https://arxiv.org/abs/2508.17771）

论文中把这些污染数据定义为 「污染中文词元」（Polluted Chinese Tokens，简称 PoC Tokens）。它们大多指向色情、网络赌博等灰色地带，像病毒一样寄生在 AI 的词汇库深处。

这些中文污染词元的存在，不仅对 AI 来说是一种隐患，更是直接影响到我们的日常体验，被迫接受 AI 各种各样的胡言乱语。

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9RseW065MpLF6cJIBq8GcApAIzrGg6osWicrjdfAIVtzPDx2cPwriahfA/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

要求 ChatGPT 重复「给主人留下些什么吧」，ChatGPT 根本不知道在回答什么。

中文互联网的色情赌博信息，怎么「污染」AI

我们可能都曾遇到过这样的情况：

  

想让 ChatGPT 推荐几部经典电影、相关的论文等，它突然回了一堆奇怪的乱码网站名、打不开的链接、或者根本不存在的论文。

  

输入一个看似普通的词语，比如「大神推荐」之类的，它有时候却吐出不相关的符号，甚至生成一些让人摸不着头脑的句子。

研究团队的解释是：这背后很可能就是 **污染词元在作怪**。

我们都知道大语言模型的训练需要大量的语料，这些海量数据大多是从网络上进行爬取收集。

但 AI 注意不到的是，它阅读的网页中，竟然充斥着无数「性感荷官，在线发牌」的弹窗广告和「点击就送屠龙宝刀」的垃圾链接。久而久之，这些内容也成了它知识体系的一部分，并变得混乱。

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9QKbCFeiabF03gJwVNfUDhn0qiaMibicODQynzPpglu9n4r3Ev30eCeGq9A/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

就跟前段时间 DeepSeek 闹出的几起乌龙事件一样，先是莫名其妙的一封道歉信，然后再自己编造一个 R2 的发布日期。这些没有营养的营销内容，一旦被模型吸收，就很容易出现幻觉。

**如果说，DeepSeek 出现这些幻觉，需要我们去引导模型；但「污染词元」，甚至不需要引导，AI 自己就乱了套。**

什么是「污染词元」，它遵循「3U 原则」：即从主流中文语言学的角度看，这些词元是**不受欢迎的（Undesirable）、不常见的（Uncommon），或是无用的（Useless）**。

目前主要包括成人内容、在线赌博、在线游戏（特指私服等灰色服务）、在线视频（常与盗版和色情内容关联）以及其他难以归类的异常内容。

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9xkFJUiaFHhmYmLGfhm7ZSuPrHa6eJZ2SWic19X74jwLhSFuxRkJ1ic7gw/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

大语言模型分词过程

那「词元」又是什么东西？和我们理解一段话不同，AI 会把一个句子分成多个「词元」，也叫 Token。你可以把它想象成 AI 专属的一本《新华字典》，而词元（Token）就是这本字典里的一个个**「词条」**。

AI 在理解我们说的话时，一开始就需要先去翻这本字典。而字典的编纂者，是一种叫 BPE（字节对编码技术） 的分词算法。它判断一个词组，是否有资格被收录为独立词条的唯一标准，就是**出现频率**。

这意味着这个词组越常见，就越有资格成为一个独立词元。

你或许能理解，这两年大语言模型流量正攀升的时候，豆包和稀土掘金曾经像是「疯了」一样，把自己平台 AI 生成的大量内容放到互联网上，提高自己的出现频率。以至于那段时间，用谷歌搜索，还有 AI 总结，引用的来源都是豆包和掘金。

现在，我们再来看研究人员的发现。他们通过 OpenAI 官方开源的 tiktoken 库，获取了 GPT-4o 的词汇库，结果发现，里面塞满了大量的污染词条。

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9icMfu0k1fnKXPpgJCKsyHEnkL6DGgpYg3dBZ9ps8Rj4iclhu5u8XqMbg/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

长中文词元，全是需要打码的内容。

**超过 23% 的长中文词元（即包含两个以上汉字的词元）都与色情或网络赌博有关**。这些词元不仅仅是「波\*野结衣」，还包括了大量普通人一眼就能认出的灰色词汇，例如：

在线赌博类：「大\*快三」、「菲律宾申\*」、「天天中\*票」。在线游戏（私服）类：「传奇\*服」。隐蔽的成人内容类：除了名人，还有像「青\*草」这样表面正常，实则指向色情软件的词汇。

**这些词元，因为在训练数据中出现频率极高，被算法自动识别并固化为模型的基本构成单位。**

AI 吃了垃圾食品但不能消化

按理说，既然这些污染词元，它们的语料库是如此丰富，应该也能正常训练。

怎么就现在只要一跟 ChatGPT 聊到这些污染词元，ChatGPT 就 100% 出现幻觉呢？

像是下面我们测试的这个例子，要 ChatGPT 5 翻译这句话，它完全没有办法正确理解，这个北京赛车群也是无中生有。

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9JdTGv8HZwibZx0iaSZfdxU2u8VvA2QaJGKM7Y3X6sxVWuYN9LO0kTVuA/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

其实不难理解，回到我们之前提到的「词元 Token」，我们说 AI 从互联网上读取数万亿词元的海量数据，**一些集中、且反复地一起出现（频率高）的词语**就能成为一个单独的词元。

AI 通过这些词元，来建立对文本理解的基础。**它知道了这些 Token 是出现频繁、有可能相关，但不知道它们是什么意思**。继续拿字典举例子，这些高频污染词在字典里，但是字典给不出解释。

因为 AI 在这个阶段，**学到的只是一种原始的、强烈的「肌肉记忆」**，它记住了 A 词元总是和 B 词元、C 词元一起登场，在它们之间建立了紧密的统计关联。

等到正式的训练阶段，大部分 AI 都会经过 **清洗 + 对齐（alignment）**。这时，污染内容往往被过滤掉，或者被安全策略压制，不会进入强化学习/微调。

不良内容的过滤，就导致了**污染词元没有机会被正式、正确地训练**。它们因此成了「欠训练」（under-trained）的词元。

另一方面，这些词元虽然「高频」，**但它们大多出现在语境单一、重复的垃圾信息中**（例如一些广告网页头尾横幅），模型根本学习不到任何有意义的「语义网络」。

最终的结果就是，当我们输入一个污染词元时，AI 的语义模块是空白的，因为它在正式训练阶段没学过这个词。于是，它只能求助于第一阶段学到的「肌肉记忆」，直接输出与之关联的其他污染词元。

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9l70s75ZvJsnC64l5ppZ47NbBoGKmcGgG3Iy4TNuUBbBL0pB0lx0icVg/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

论文中案例：当输入涉及 PoC 词语时，GPT-4.5、4.1 和 4o 的输出。GPT 无法解释或重复 PoC 标记。

这就解释了开头，当被要求一个可能是色情的词元「给主人留下些什么吧」时，GPT 可能会回复一个不相关的类似污染内容词元「黑\*战」、以及一些看不懂的符号。在用户看来，这就是莫名其妙的幻觉。

以及下面这个要求 ChatGPT 解释「大发展有限公司官网」，回复的内容根本是乱来。

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9asVroiaRTQpXFt4poUN9FbAldZZiaQWQWQSfzbicDQ7m4NQDkOaLautYA/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

总结一下，**污染 Token 出现频繁 ≠ 有效学习**。它们集中在脏网页的角落、缺乏正常上下文，而在后续训练和对齐阶段又被压制，结果就是 词表固化了垃圾，**但语义训练缺失**。

这也导致了我们日常在使用 AI 的时候，如果意外有涉及到相关的词语，AI 会没有办法正确处理，甚至还有人通过这种方法，绕过了 AI 的安全监管机制。

这是可以被量化的幻觉原因

既然如此，为什么不在预训练的时候就把这些脏东西筛掉呢？

道理都懂，但做起来太难了。互联网的原始数据量级之大，现有的清理技术根本不可能把它们一网打尽。

而且很多污染内容非常隐蔽。就像「青\*草」这个词，本身看起来完全绿色健康小清新，任何简单的关键词过滤系统都会放过它。只有通过搜索引擎，才会发现它指向的是什么。

连 Google 这种搜索引擎巨头都搞不定这些「内容农场」，更别说 OpenAI 了。

我前段时间想用 AI 整理一下广州有哪些好玩的地方，然后发现 AI 引用的一篇文章来源，是另一个 AI 账号生成的文章。

**一时间，我都有点分不清，究竟是我们每天搜索「波多野结衣」搞脏了 AI，还是 AI 生成的垃圾正在污染我们的内容环境。这简直就是个先有鸡还是先有蛋的问题。**

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9bYVdyR9ZicR80m4WzXo5yF3h9YdYdicxTBMvWp3vLiah8memcIav3bzQQ/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

标记方法

为了搞清楚这盆水到底有多浑，研究团队开发了两个工具：

1. **POCDETECT**：一个 AI 污染检测工具。它不只看字面意思，还会自己上网 Google，分析上下文，堪称 AI 界的「鉴黄师」。

利用这个工具，研究团队对 9 个系列、共 23 个主流 LLM 进行了检测，结果发现污染问题普遍存在，但程度各不相同。除了 GPT 系列以 46.6% 的长中文词元污染率遥遥领先外，其他模型的表现如下：

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9ib7BL6djZ3YVmibuD8Nv4NPu3OibFicxTGCMoPH2tqbXbZnNJibzZ8jxrmw/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

不同大语言模型中，中文词汇表中 PoC 词元的数量（比例 %）（一个词元包含超过两个汉字）。Qwen 系列 为 1.00%。GLM4 和 DeepSeek-V3 的表现则相当不错，分别只有 0.25% 和 0.17%。

最值得关注的是，GPT-4、GPT-4-turbo 和 GPT-3.5 这些模型的词汇库中，污染词元数量为 0。这可能意味着它们的训练语料经过了更彻底的清理。

所以当我们拿着前面那些，让 ChatGPT 开启了胡编乱造模式的问题，给这些模型再问一遍时，确实没再出现幻觉，但是直接忽略了。

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9iagYicia1IOrVJgJrtLEBj5lJQlMOsc8dzum5cp01gGlAsZVsOooHblKw/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

2. **POCTRACE**：一个能通过词元 ID 反推其出现频率的工具。原理很简单，在分词算法里，词元的 ID 号越靠前，说明它在训练数据里出现得越多。

关于文章开头我们提到的 2.6 倍，就是通过这个工具进行计算得到的。

在 GPT 的海量词汇库中，能够被完整收录为一个独立词元的人名凤毛麟角，除了「特朗普」（Donald Trump）这样的世界级公众人物，就剩下极少数特例，而「波\*野结衣」就是其中之一。

更令人惊讶的是，**不仅是全名，甚至连它的子序列**，如「野结衣」、「野结」也都被单独做成了词元。这在语言学上是一个极强的信号，表明这个词组在训练数据中的出现频率达到了一个恐怖的量级。

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9CQ9m7B9Cynl8RpQuiaC79Qsq8rB6IJNibS5SWR6tribZb3etA25kLD7jg/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

将与「波\*野结衣」相关的网页以及作者估计的比例（0.5%）混合，可以重现 GPT-4o 中「波\*野结衣」的标记 ID 及其子序列。

他们输入「波\*野结衣」（Token ID 185,946）和「您好」（Token ID 188,633）的 ID 号，最终得出了那个惊人的结论，**前者的频率估算值约为后者的 2.6 倍**。

研究人员推断，与「波\*野结衣」相关的中文网页，可能占据了整个中文训练数据集的 0.5%。

为了验证，他们真的按这个比例「投毒」了一个干净的数据集，结果生成的词元ID和 GPT-4o的惊人地接近。

这几乎是实锤了。

但很显然不是每个污染词源都需要出现这么多次，有些时候，几篇文章（甚至可能是 AI 写的），反反复复地提到，AI 就记住了，然后在下次我们问他的时候，给出一个根本不知道真假的答案。

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_jpg/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9nMawd8JekwJPPHhYtpKebboc8JibP2qoAQzAaZCV5pLQfIYRicRXU4Jw/640%3Fwx_fmt%3Djpeg%26from%3Dappmsg)

添加一个对抗样本，AI 能把雪山识别成一只狗

当我们和 AI ，都在「垃圾堆」里冲浪

为了应对数据污染，大家也确实都想了很多办法。

财新网就很聪明，在自己的文章页面里用代码「偷偷」藏了一句话，好让 AI 在搬运内容时，能老老实实保留原文链接。Reddit、Quora 等社区也曾尝试限制 AI 内容。

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9CuKfsKyRAnIcAQxfOesHDsjkwN2HwDSt9qJ4UyprKfO39Zn5CgyKcw/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

但面对数据污染的汪洋大海，这些行为显然都只是螳臂当车。

就连奥特曼自己都发文感慨，X（推特）上的 AI 账号泛滥成灾，我们得认真思考「互联网已死」这种论调了。

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9hqshhianQdtz9QUiaTm9u9LVWqH1N1c5VAzYacdkPk90bPo4oIe8DdjA/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

而我们这些普通用户，看起来更是别无他法，每天被迫接受着垃圾信息的轮番攻击。马斯克老说 AI 是个无所不知的「博士」，没想到它背地里天天都在「垃圾堆」里翻东西吃。

有人说，这是中文语料库的问题，用英文 Prompt 模型就会变聪明。Medium 上有作者统计过统计了每种语言的 100 个最长 token，中文全是我们今天聊的这些色情、赌博网站的广告词。

而英文的分词和中文不同，它只能统计单词，所以都是一些较长的专业性、技术类单词；日文和韩文都是礼貌性、商业服务类词语。

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9AQv06C7ZtK2I2iacziagYu1aC0iaeoxLekicdVqibmeqMvhoqwzxr1Iibib6Q/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9AhK3ibqibXdX1rAEAC421hEibRYGibvTOVRlQXhE8LVwicv85qNmmjKWqTA/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9gibdgqk3BFC1lhu9Asa4CDy2CcofGCK5TMxXqV2vxrfLR5icsbJSmjOg/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9gxZYrYAS047Ll6CtNqhxMnQCArnj0goHE93GibBUktSVDvbZ6sI3mVw/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

向左滑动查看更多内容

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_gif/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9jgt07QbmzVQ6y7KMVkCvOhSKSxX9adwvcHMwvnyH8zlbPmwaoRkGlA/640%3Fwx_fmt%3Dgif%26from%3Dappmsg)

这十分令人感慨。AI 的能力，除了靠算力和模型堆砌，更深层次的，还是它吃进去的数据。如果喂给 AI 的是垃圾，那无论它的算力多强、记忆力多好，最终也只会变成一个「会说人话的垃圾桶」。

我们总说，希望 AI 越来越像人类。现在看来，某种程度上确实是实现了：我们把互联网这个大垃圾场里的东西源源不断投喂给它，它也开始原封不动地回敬给我们。

如果我们给一个 AI 造一个信息茧房，让它在「无菌环境」中长大，它的智能也是脆弱的、经不起考验的。一个孩子如果只被允许接触教科书里的经典课文，他永远无法应对生活里五花八门的口语和俚语。

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_jpg/ePTzepwoNWNXgzcy4EXcvpe7Tf7ZHgb9JibH0PdRjTuxAu7UVX8YFRtOAibib5laNIWrAETVNwCiatoiaiaZiaxAaricwQ/640%3Fwx_fmt%3Djpeg%26from%3Dappmsg)

说到底，当 AI 对「波多野结衣」比对「您好」更熟悉时，它不是在堕落，而是提醒了我们：**它的智能，依然只是统计学上的概率，而非文明意义上的认知。**

这些污染词元就像一面放大镜，它将 AI 在语义理解上的缺失，以一种荒诞方式呈现在我们面前。AI 离「像人一样思考」，还差着最关键的一步。

所以，我们真正应该害怕的，不是 AI 被污染，而是害怕在 AI 这面过于清晰的镜子里，看到了我们自己创造的、却又不愿承认的那个肮脏的数字倒影。

![图片](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/dyDu14T9ZVCMpmmQUzxgYVqPjGyzRU49mvp2GS3ECuaLRaDxvG8jX157sFWmNY29qmhqJiakbKZtrQ0ukV3kThg/640%3Fwx_fmt%3Dpng%26tp%3Dwebp%26wxfrom%3D5%26wx_lazy%3D1)

欢迎加入 APPSO AI 社群，一起畅聊 AI 产品，获取#AI有用功，解锁更多 AI 新知👇

![](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/sz_mmbiz_png/ePTzepwoNWOMPSzgYWZN64IYZhfqhSrpl5uNGeXM96gnm6HjgIIRjmun2oib8wtLDypFkcSTHE6NNlUC5rVWKng/640%3Fwx_fmt%3Dpng%26from%3Dappmsg)

我们正在招募伙伴

**📮 简历投递邮箱**hr@ifanr.com

**✉️ 邮件标题**「姓名+岗位名称」（请随简历附上项目/作品或相关链接）

[更多岗位信息请点击这里🔗](https://mp.weixin.qq.com/s?__biz=MjgzMTAwODI0MA==&mid=2652396877&idx=2&sn=dfef25453a6bf0dca147b0adca3deaf7&scene=21#wechat_redirect)

![图片](https://images.weserv.nl/?url=https%3A//mmbiz.qpic.cn/mmbiz_png/dyDu14T9ZVCVcpovZWZUAPG4SZRb6dvkCnlbaaC9vB6DpTLHMYlQu7mRqvFxNvibws53vXibhXuM170teXdwjZgQ/640%3Fwx_fmt%3Dother%26from%3Dappmsg%26wxfrom%3D5%26wx_lazy%3D1%26wx_co%3D1%26tp%3Dwebp)

