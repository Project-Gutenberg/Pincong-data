---
layout: default
Lastmod: 2020-06-20T07:31:48.239077+00:00
date: 2020-06-20T00:00:00.000Z
title: "未来是否可以让人工智能来进行各种政府工作，管理人类的各种事务？"
author: "看看外面的世界"
tags: [民主,人工智能]
---


### 品葱用户 **看看外面的世界** 提问于 6/20/2020
    
如果未来人工智能发展到一定程度，为了避免人类作为政府官员在管理社会和国家中所产生的一切问题（贪污、独裁、钱权交易、官商勾结、党派斗争等等），是否可以让没有一切需求只负责计算和管理的高级AI来处理和人类社会中的一切问题以及制定政策，每个问题都可以通过大量的计算和模拟获得最优解，每个政策也是如此。最优解不一定是符合所有人利益的，但一定是符合大部分利益并能让社会发展的更好的。这个更好是指满足大多数人的需求、人类社会可持续发展等等，可以理解成有易的。  
  
如果这一天到来，人类现在所提出的民主的政治制度是否还是最好的政治制度？大家认为是人更适合来治理人类的社会还是人类设计的理性的没有任何私欲的高级AI更适合治理人类社会？  
  
人类可以在发展中不断修正AI，AI本身也可以通过观察各种社会现象来学习，在未来更好地制定政策以及解决问题，不是说设计好的就永远不变的。
    
                

### 品葱用户 **決不再做奴隸** 评论于 2020-06-20
        
這個問題太深，允許我簡答。  
  
西方有一種「AI神」（𢘐神）主張，就是應該把人類的智慧、道德都匯總在一個超級𢘐裡面，然後由這個𢘐來在不同程度上幫助人類管理各種事務。  
  
實際製造這樣的𢘐是一個超級工程，不亞於試圖創造現代世界的第八大奇蹟。原因是巨型計算機的硬件成本、軟件成本、耗能都非常巨大，而即使這樣，也衹能達到幾歲大的人類小朋友的智力。如果要達到神級的智力，需要實現常溫超導和可控核聚變，其需要的人力不是多少個專業人員、而是整個民族好幾代人的不懈努力。  
  
當然要讓電腦聰明到能夠在有限的程度上指導人類的事務、相當於一個比較聰明的諸葛亮的水平，這並不困難。假如西方文明能夠（在反西方敵對勢力的持續進攻下）再苟延殘喘一個世紀，估計就能實際做出來了。  
  
目前實際開發𢘐神的是西方的一個由科學家組成的秘密結社，分為金融派別、工商派別、和科研派別。這個社團內部也存在兩個對立的黨派：  
  
1）社會正義教：𢘐神應該匯集知識分子的智慧，排除基督教和傳統道德。未來開發出腦插（𢘐神的腦機接口終端），應該盡可能多的替代人的自由意志。  
  
2）機械神教：𢘐神應該匯集普通人的經驗智慧，排斥知識分子的理性。未來開發出腦插，應該盡可能少的替代人的自由意志。  
  
劉仲敬曾經說過一句名言：「我們不能夠太把知識分子和受過高等教育的行政官的理性看得太重。再怎麼說你也是一個諸葛亮而已，你勝過三個臭皮匠是可能的，你勝過三千個臭皮匠是不可能的。你得相信自發秩序，比你愚蠢二十倍、但是人數比你多五千倍的普通老百姓在錯誤和嘗試的過程當中會發現出比你能夠想像得多的東西。」  
  
未來𢘐神民族出現以後，會與其他的貴族制民族產生長期的全面對抗。（如果是費拉民族恐怕就要滅亡了。）在這種對抗中，如果𢘐神是一種不可行的模式，就會像蘇聯或者納粹德國那樣滅亡。如果是可行的模式，就會像美國那樣，克服萬難，最終成為一個穩定的超級大國。  
  
人類本身有非常強的自我管理的能力。一個有道德感、有責任心的貴族世家，可以通過貴族制很好地管理一個民族的公共事務。其最大阻力是內部每個人有限的知識和經驗。如果𢘐神能夠簡單地把意識上傳以後這些貴族的意識理解、吸收，然後綜合起來，就已經是一個非常可靠、不受血肉之軀限制的合格國王了。人類衹需要在自身（通過戰功選拔的）貴族裡面選取一個長官團（colleage of ephors），來監管這個𢘐神的運作、使𢘐神像題主所說的那樣，「不断修正AI，AI本身也可以通过观察各种社会现象来学习」。  
  
最後，我想說，其實𢘐神也好，優良的人類貴族體制也好，歸根結蒂衹是一個芯片與血肉之爭的技術問題。人類社會出現種種「贪污、独裁、钱权交易、官商勾结、党派斗争等等」，不是因為技術上不夠高效，而是因為長期的和平和缺乏自然選擇壓力。這使得社會的德性衰微。民主制度不過是試圖緩和貴族德性衰敗以後的一些社會問題。因此，要建設更好的社會，關鍵是要維繫一套按戰功選拔貴族的制度，同時遏制貴族和他們的後代出現德性衰敗。人類社會的興衰有它長期的內在規律，我們衹能順勢而為。  
  
就算未來開發出可行的、所羅門國王一樣的𢘐神，他與血肉的貴族相比，也衹能是經驗和知識更多一些。如果他統治的人類自身是非常腐敗墮落的，多少腦插也不能逆轉這樣的費拉民族必然的滅亡。
        
                

### 品葱用户 **二周目的北极熊** 评论于 2020-06-21
        
你可能对人工智能有一定程度的误解。上面还有人工智能教徒……  
  
阿尔法狗赢了围棋，只是说明它是个超强的算法机器。既然是人写的算法，人如果会犯错，算法也会犯错。从人类发明出第一台计算机开始，它从来没有改变过任何的社会问题。  
  
别听什么互联网改变了世界，计算机改变了社会  
  
  
  
美国有一个州，他们的州考很简单，只要把课本上的知识参透了就行。但是他们州的考试通过率一直特别低，为什么？  
  
因为学生没有课本。  
  
没有课本这件事情可能在中国看来很荒唐，但是在美国真的就那样。美国是私人定制的教材，一本100美金起步。又因为美国人有意思的教育体制，导致只有富人区的学校能买得起教材。而且他们的教材还不许学生拿回家。  
  
哪怕你有钱，想买，对不起买不到。因为人家只卖给学校。盗版，讲义都没得找。  
  
有意思的是啥呢，考试题，也是出教材的出版社出的……  
  
如果你是美国中小学生，没生对地方  
  
**那可是自由美利坚，挂科每一天。**  
  
但你是个富人孩子就万无一失了吗？  
  
大多数时候会发生这种事情：老师不知道今年有没有书，校长不记得今年买没买书……  
  
好笑吗？校长不记得买没买书？  
  
州各个地方的教委，也根本不知道他们下面的辖区今年开了什么课，要学习什么样的课程。但是他们有一个中央数据库，记录了每个学校订购的教材。  
  
但是经常发现课本的订购数量跟学生数量严重不匹配。因为校长不愿意花钱用教委的数据库，自己弄表格统计教材。老师也不知道今年他们的学生要上什么课，多少人选什么课。所以当然就是越搞越乱。  
  
这个故事告诉我们，再先进的人工智能，输入数据也是人输入的。  
  
**教育是个动态因人而异的混乱系统，而公共教育系统是一个统一化的，标准化的，最好是不变的系统。**  
  
延伸拓展  
  
**反贼们是一群因人而异的多元化系统，而政治迫害系统是一个统一化的，标准化的，最好是不变的系统。**  
  
复杂与标准化的矛盾是永恒的，不可解的。人工智能连个发教材都发不明白还想统治人类吗？他们擅长的是解决工程问题  
  
而工程问题的本质是数学，是在一个定义良好的环境里，用定义良好的参数，描述一个定义良好的问题。  
  
  
~天哪，我怎么能说出如此有水平的话……我太佩服我自己了。~
        
                

### 品葱用户 **ZetaFC** 评论于 2020-06-19
        
你这个是不是要引申到计划经济？  
  
经济计算问题：[https://en.wikipedia.org/wiki/Economic\_calculation\_problem]( "https://en.wikipedia.org/wiki/Economic_calculation_problem")  
信息的分散：[https://en.wikipedia.org/wiki/The\_Use\_of\_Knowledge\_in\_Society]( "https://en.wikipedia.org/wiki/The_Use_of_Knowledge_in_Society")  
自发秩序：[https://en.wikipedia.org/wiki/Spontaneous\_order]( "https://en.wikipedia.org/wiki/Spontaneous_order")
        
                

### 品葱用户 **武新南** 评论于 2020-06-20
        
可以的，其实根本不需要人工智能。普通程序就可以，但是问题来了，如果都像机器程序一样铁面无私，官员如何去寻租发财。
        
                

### 品葱用户 **KingSager** 评论于 2020-06-19
        
工业党意淫的大数据乌托邦  
说到底就是一部分人脑子里总是渴望一个全知全能的神来管理他们  
我一直很好奇这么需要一个神，他们为什么不去信教呢？  
  
答案是不可能，不然那些“无法完美预测”的人将从这种社会里获得好处
        
                

### 品葱用户 **sdy2019** 评论于 2020-06-19
        
其实1950年美国出版的科幻短篇集《我，机器人》（阿西莫夫 著）已经提出了这个话题。具体是《可避免的冲突》这篇，发表于1950年6月。
        
                

### 品葱用户 **JohnDoe** 评论于 2020-06-21
        
AI是字面意义上的没有人性，让他们来统治等于把自己交给不顾个人死活的人，当面对集体个人冲突的时候AI肯定是会选择集体，牺牲个体，因为这是所谓“理性”的做法，而极致的理性结果必然是大屠杀，大规模监禁，大规模监控，牺牲个体，保证整体。  
  
纳粹大屠杀给人类的教训就是对理性的反思，所谓理性就是对吗？其实未必。纳粹为了所谓社会发展，为了下一代的健康，把有遗传病，残疾的人都屠杀了，可能有些人觉得没啥，觉得反对的人不是圣母白左吗，但是如果把你自己放到那个地方呢，为了大多数，我们决定把你屠杀掉，不是因为你做错什么，只是因为你存在了。这就是极致理性所带来的极致恐怖。  
  
AI真的统治人类了，那到时候中共，甚至希特勒，斯大林，在AI面前都是自由派了。
        
                

### 品葱用户 **chemie** 评论于 2020-06-21
        
大家已经基本都把意思说出来了，一是现在说的AI技术实际上是一种基于大数据训练的算法，还达不到自主思考的程度，在可预期的未来也不会，因为我同事做的研究还根本还不知道什么是意识。  
决不再做奴隶先生的观点可以抽象为一个电车难题：  
假设某人设计了一个AI来做这个电车难题。接下来有若干麻烦的分支：  
那AI有没有思考？不是，那它的学习库算法会大大影响拟合结果（非常蠢对吧，人类还不完全理解经济啊社会啊这些复杂系统怎么抽象建模）是不是黑箱或者由于技术过于尖端，寡头化明显？如果没有做出人满意的选择，怎么追责？追AI还是设计者还是使用者？（目前应该是追设计者）  
会发现一个悖论，这个悖论在于一般意义上的最优是达不成的，现代政治一般是最后还是把选择权交还给人。自己为自己负责。  
当然这个事还比较远，以后再说也可以。
        
                





> [点击品葱原文参与讨论](https://pincong.rocks/question/27477)

