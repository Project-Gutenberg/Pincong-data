---
layout: default
Lastmod: 2020-06-21T13:51:14.626664+00:00
date: 2020-06-21T13:51:12.613346+00:00
title: "为什么事实不能改变我们的想法？"
author: "伊丽莎白·科尔伯特
　　王培/译"
tags: [学生,受试者,研究,死刑,消防员,马桶,理性,思维方式,新语丝]
---

为什么事实不能改变我们的想法？

作者：伊丽莎白·科尔伯特　　王培/译 培理讲到底

本文译自《纽约客》。作者伊丽莎白·科尔伯特，自1999年起为《纽约客》撰写专栏文章，凭借非虚构作品《大灭绝时代》（The Sixth Extinction: An Unnatural History）荣获2015年普利策奖。奥巴马和比尔·盖茨都是《大灭绝时代》的忠实粉丝。科尔伯特擅长通过讲故事或者运用现实案例来表达观点、传播思想，《大灭绝时代》如此，本文同样如此。不读到最后，你根本不知道这其实是一篇政论文章！至于科尔伯特在本文中所展现出来的信息整合能力和观点表达技巧，作为普利策奖得主，大家自己读完，自己体会吧！如果没体会到，那只能说明………………是译者翻译的问题！

（本文不用于商业目的，仅供交流学习）

1975年，斯坦福大学的研究人员邀请一组本科生参加了一项关于自杀的研究。每个学生手里都握有若干对自杀遗书。每一对遗书中，有一张的内容是某个人随意写上去的，另一张的内容则是真实的自杀者所写的。研究人员要求学生们分辨出真的遗书和假的遗书。

有些学生发现，他们很擅长这项任务。在25对遗书中，他们正确地分辨了24对。而另一些学生则对自己的工作深感失望，他们只正确分辨了其中10对。

与通常的心理学研究一样，这次研究的整个过程是一场精心安排的“骗局”。尽管的确有一半的遗书是真实的——它们是从洛杉矶郡丧葬机构那里获得的——但学生所得到的测试成绩却是假的。平均而言，被告知几乎全部辨认成功的学生并不比被告知多数都辨认失败的学生具有更好的辨认能力。

在这项研究的第二阶段，研究人员向学生们曝光了第一阶段的“骗局”，然后告诉学生，第一阶段研究的真实目的在于，在研究人员人为认定他们辨认成功或失败之后，测试他们的反应（当然，这一说辞也是假的）。最后，研究人员要求学生们预测他们真正成功辨认了多少次，以及所有学生成功辨认的平均次数。这个时候，奇怪的事情发生了。第一阶段成绩得了高分的学生相信，他们事实上很好地完成了辨认工作——比平均成绩要高得多——尽管不久前他们才被告知，他们与其他学生的成绩没有多少差异。相反，第一阶段成绩得了低分的学生则相信，他们的真实成绩比平均成绩要低得多。然而，得出这一结论同样毫无根据。

研究人员敏锐地观察到：“一旦形成先入之见，这种成见就会相当顽固。”

几年后，又有一组新的斯坦福大学学生被招募从事一项相关研究。学生们拿到了两个消防员的一组信息，一个名叫Frank K.，一个名叫George H.。Frank的个人信息显示，他有一个年幼的女儿，他还很喜欢潜水运动。而George有一个年幼的儿子，他很喜欢打高尔夫球。研究人员对两个消防员进行了风险偏好测试，提供给学生的信息中包括了消防员对该测试的反馈。根据其中一个反馈版本，Frank是一个成功的消防员，因为他几乎总是作出最安全的选择。而根据另一个反馈版本，Frank是一个失败的消防员，他几乎总是作出最安全的选择，但却因为这么做而被他的上司警告过若干次。研究进行至此，学生们再次被告知，他们所得到的信息全部是假的。然后，研究人员要求学生描述他们对于消防员的看法：他们认为一个成功的消防员对待风险应该具备什么样的态度？得知第一个反馈版本的学生认为，成功的消防员应该回避风险。得知第二个反馈版本的学生则认为，消防员应该拥抱风险。

研究人员发现，尽管学生们已经被告知“他们所获得的信息完全是假的，他们还是没有对自己的看法做出适当的调整”。在这一案例中，学生们的表现“尤其反映了他们的先入之见”，因为前后两组矛盾的信息根本不足以让他们得出明确的结论。

斯坦福大学的这项研究很快就出了名。1970年代的学术界对于人们无法做到理性思考感到十分震惊，而现如今的学术界对此早已不再惊讶。之后数千项实验证实了（详细阐明了）这一发现。正如每一个跟进这项研究——或者是偶尔浏览《今日心理学》（Psychology Today）期刊——的人所知道的那样，任何一个心理学研究生都能证明，貌似很理性的人通常完全不理性。这一洞见尤其适用于今日世界。然而，一个根本的困惑在于：我们为什么这么不理性？

在新书《理性之谜》（The Enigma of Reason）（哈佛出版社出版）中，认知科学家Hugo Mercier和Dan Sperber试图回答这一问题。Mercier在法国里昂的一家研究机构工作，而Sperber现就职于位于匈牙利的中欧大学（Central European University）。他们指出，理性是进化的产物，就像双足行走或三色视觉一样，它产生于非洲的热带稀树草原。人们必须从进化的角度去理解理性。

忽略认知科学方面的专业术语，Mercier和Sperber的论证大致如下：人类相比其他动物的最大优势在于，人类具有合作的能力。合作通常难以建立，而且也很难维系。对任何个人而言，“搭便车”总是最理想的行为。人类最早发展出理性不是为了让我们解决抽象的逻辑问题，或者帮助我们从不熟悉的数据中总结出规律，而是为了帮助我们解决在集体合作中所遇到的问题。

“理性是从高度社会化的人类中进化出来的”，Mercier和Sperber写道。有些心智习惯在知识分子看来显得十分怪异、愚笨或呆拙，但从社会互动的角度来看，它们的存在却是很合理的。

回想一下著名的“确认偏见”(confirmation bias）：人们总是倾向于接受支持他们信念的信息，而拒绝与他们所持信念相反的信息。在已经被证实的很多错误的思维方式中，“确认偏见”是最常见的一种，围绕它所展开的实验简直可以写出一整本心理学教材。其中最有名的一项实验就出自斯坦福大学。在这项实验中，研究人员召集了一组学生，这些学生在死刑问题上持有相反的观点。一半学生支持死刑，认为死刑可以阻止犯罪；另一半学生反对死刑，认为死刑对于阻止犯罪没有效果。

这些学生被要求对两项研究作出回应。一项研究提供了支持死刑的证据，另一项研究提供了反对死刑的证据。两项研究——你已经猜到了——都是人为炮制出来的，只是为了用于公正无偏地——正反两方的证据分量相同——呈现具有说服力的证据。结果表明，一开始就支持死刑的学生认为阻止犯罪的证据更可信，而未能阻止犯罪的证据不可信；而一开始就反对死刑的学生则相反。实验快要结束的时候，研究人员再次让学生确认自己的立场。那些一开始就支持死刑的学生更加坚定地支持死刑，而那些反对死刑的学生则更加坚定地反对死刑。

如果理性是自然选择所“设计”出来的产物，它的出现是为了产生可靠的判断，那么，很难想象有比“确认偏见”更糟糕的设计缺陷了。Mercier和Sperber说，设想有只老鼠，其思维方式与人类一样。如果这只老鼠“倾向于确信它周围没有猫存在”，那它很快就会成为猫的盘中餐。某种程度上说，“确认偏见”使人们忽视了新的证据或潜在的危险——与猫对老鼠的危险类似，可以对人类产生危险的事物无处不在——它应该被自然选择所淘汰。然而，Mercier和Sperber争辩说，既然人类和老鼠还能生存得很好，这一事实表明，“确认偏见”一定有某种适应性功能，他们认为，这种功能与人类的“高度社会性”有关。

Mercier和Sperber更喜欢用“自我偏见”（myside bias）这一术语。他们指出，人类不会随便相信他人。如果将他人的观点摆在我们面前，我们很容易发现他人观点的缺陷。然而，几乎可以肯定的是，我们却盲目相信自己的观点。

最近，Mercier和她的一些欧洲同事进行了一项实验，巧妙地证实了这种非对称性。受试者被要求回答一系列简单的推理问题。然后，他们需要解释他们给出的答案，如果他们发现回答错了，可以有机会修正答案。大多数受试者认可他们给出的第一个答案，只有不到15%的受试者修正了他们的答案。

接下来，受试者再次被问到同样的问题。然后，研究人员向他们显示了他们自己给出的答案和另一个受试者给出的答案——一个完全不同的答案。再一次，研究人员给了机会，受试者可以改变自己的答案。不过，这里设置了一个陷阱：研究人员显示给受试者的另一个答案（即完全不同的答案）正是他们自己给出的答案。有一半的受试者意识到发生了什么，而另一半受试者则突然更加猛烈地批判起自己给出的答案。最终，将近有60%的受试者放弃了他们之前所给出的答案。

在Mercier和Sperber看来，这种非对称性反映了，由进化而来的理性试图阻止我们被其他人欺骗。生活在狩猎社会，我们祖先首要的关切是他们的社会生存地位，他们要确保自己不成为社会的牺牲者——自己被安排去捕猎，而其他人则坐享其成。即便通过清晰的理性思辨赢得争论会有很多好处，但在那个物质贫乏的年代，在社会化的生活环境下，理性很少能为个人带来生存优势。

在许许多多的问题上，我们的祖先从不会为了死刑的效果、消防员的理想特征而感到焦虑。他们也不必非得为了复杂的学术问题、假新闻、Twitter信息而争论不休。因此，毫不奇怪，理性在今日世界仍然受到挫败。正如Mercier和Sperber写道：“有很多案例表明，现实环境变化太快，而自然选择还没跟得上节奏，理性的失败就是其中一个例子。”

Steven Sloman，布朗大学教授和Philip Fernbach，科罗拉多大学教授都是认知科学家。他们也相信，社会性是人类心智发生作用的关键，或者，也可以说，是人类心智失调的关键。在他们所写的《知识幻觉：为什么我们不可能独自思考》（The Knowledge Illusion: Why We Never Think Alone）（Riverhead出版社出版）一书中，他们以马桶实验作为故事的开篇：

在美国，实际上在所有发达国家，每个人都知道马桶是什么。一个典型的冲刷马桶有一个装满水的陶瓷桶，当把手被按下，或者按钮被推压，水——以及桶里的所有东西——被吸进了管道，然后从管道流进了下水道。但是，马桶的运作机制究竟是什么呢？

在耶鲁大学的一项研究中，研究人员要求研究生们按照他们对日常生活设备的了解程度进行排序，包括马桶、打火机和圆筒锁。他们需要详细地一步步地写出这些设备是如何运作的，然后，他们要根据对设备运作了解程度的高低进行排序。显然，这个实验揭示出了学生们对设备的无知，因为他们的自我评价都下降了（实际上，马桶的运作原理比他们想象的要复杂得多）。

Sloman和Fernbach发现，这种心理效应无处不在，他们把它称之为“深度理解的幻觉”（illusion of explanatory depth）。人们相信，自己所知道的比实际所知道的要多。而让我们坚持这种信念的正是缘自于其他人。在马桶案例中，有人设计出了马桶，因此，我们能很容易地使用它，这是人类很擅长的事情。合作狩猎是人类进化史上至关重要的一步，自打那时起，我们就开始依赖他人的专业知识。Sloman 和 Fernbach认为，人类的合作如此紧密，以至于我们很难区分哪些属于我们的知识，哪些属于别人的贡献。

他们写道：“当我们想用一种自然的方式区分认知贡献时，我们发现，在一个人的思想和知识与同一个群体中的其他人的思想和知识之间，并没有明显的界线。”

这种无界性，或者，如果你喜欢，这种交叠，对于我们所谓的人类社会的进步而言至关重要。当人们为一种新的生活方式发明了新的工具时，他们同时就创造了新的无知的领域。如果每个人都坚持认为，比如说，在使用刀具之前必须熟练掌握炼钢的原理，这种想法在青铜器时代并无大碍。涉及到新技术时，对技术的不完全理解也并没有什么大问题。

然而，在Sloman 和 Fernbach看来，当问题涉及政治领域时，不完全理解就让我们陷入了麻烦。我们可以不知道马桶运作的原理，这毫不影响我们使用它。但当我们在支持（或反对）移民禁令时，我们不知道我们支持或反对的理由是什么，这就是另外一码事了。Sloman 和 Fernbach援引了2014年的一项调查，该调查是在俄罗斯侵犯乌克兰领土克里米亚之后不久进行的。受试者被问及他们认为美国会如何应对这一事件，以及他们是否能在地图上找到乌克兰在什么地方。结果显示，越是对地理无知的人，越倾向于支持军事干预（受试者完全搞不清楚乌克兰的位置在哪里，他们猜测乌克兰与美国距离的中位数与正确数值相差了1800英里，大约是从基辅到马德里的距离）。

关于其他问题的调查同样产生了相似的令人沮丧的结果。“作为一种现象，人们对于问题的强烈情绪并非来自对于问题的深度理解”，Sloman 和Fernbach写道。在这里，我们对于他人看法的信赖进一步恶化了这种现象。如果你关于，比如说，奥巴马医疗法案的立场是毫无根据的，而我又信赖你的看法，那么，我的立场也会是毫无根据的。当我跟Tom谈论医疗法案时，他决定认同我的看法，他的立场也是毫无根据的，但现在，我们三个人达成了一致，而且我们对我们的立场感到自鸣得意。如果我们现在把所有与我们立场相反的信息都视之为不可信的话，那么，你就已经理解特朗普政府的所作所为了。

Sloman 和Fernbach观察道：“这就是为什么群体知识会变得如此危险。”他俩做了一个自己版本的马桶实验——用公共政策取代了家庭用具。在2012年进行的一项研究中，他们询问人们在如下问题上的立场：应该建立一个单一保险人医疗体系吗？应该基于学生的考试分数决定老师的薪酬吗？受试者被要求根据他们同意或反对的强烈程度对他们的立场打分。然后，他们需要尽可能详细地解释执行每个政策所带来的影响。大多数人在这个环节都陷入了麻烦。当研究人员要求受试者再次对他们的立场打分时，他们对政策的情绪缓和了许多，无论是同意的情绪还是反对的情绪。

Sloman 和Fernbach把这一效应看作是黑暗世界的一丝光明。如果我们——或者我们的朋友，或者CNN上的专家——少把时间花在表达武断的观点上，更多地思考政策建议的影响，我们就会意识到，我们的观点有多么武断，进而可以修正我们的看法。他们写道：“这可能是唯一一种可以粉碎‘深度理解的幻觉’和改变人们态度的思维方式。”

有一种看待科学的方式：将科学看成是可以修正人们的自然倾向的体系。在运转良好的实验室里，“自我偏见”没有生存的空间；实验结果必须可以在其他实验室里得到动机独立的重复验证。正是因为这一机制，科学体系才能获得如此巨大的成功。在任何时刻，某个科学研究领域都充满了争论，但最终，科学方法还是取得了胜利。即便我们的思想仍然停留在原地，科学仍会滚滚向前。

在《拒绝死亡：为什么我们会忽视那些能够救命的事实》（Denying to the Grave:Why We Ignore the Facts That Will Save US）（牛津大学出版社出版）一书中，Jack Gorman，一个精神病医生，和她的女儿Sara Gorman，一个公共健康专家，探讨了科学告诉我们的事实和我们告诉我们自己的事实之间的差异。她们关注的是人们的固执观念，这些观念不仅被证实是错误的，而且还具有潜在的致命威胁，比如，很多人相信疫苗是很危险的。实际上，危险的并不是注射疫苗，疫苗的产生正是为了减少生命面临的危险。“免疫法是现代医学的重大胜利”，Gorman母女写道。但无论有多少科学研究证实疫苗是安全的，疫苗和自闭症之间没有因果关系，反疫苗人士仍然不为所动（现在，他们可算是找到同伙了——某种意义上——唐纳德·特朗普曾经说过，尽管他和他的妻子让他们的儿子Barron注射了疫苗，但他们拒绝按照儿科医生给出的时间表注射。）

Gorman母女还认为，看起来是自我毁灭式的思维方式一定在某种程度上具有自适应性。她们还在书中花了大量篇幅探讨“确认偏见”，她们认为，这种偏见具有心理上的原因。他们引用的研究表明，当人们在处理支持他们的信念的信息时，他们经历了真实的愉悦感——多巴胺的释放。她们观察道：“即便我们的信念是错的，坚持我们的信念仍然让我们感觉良好。”

Gorman母女并不只是想指出我们有哪些错误的思维方式，她们还希望人们能修正这些方式。她们认为，一定有某种思维方式可以说服人们相信，疫苗对孩子是有好处的，持有枪支是很危险的（还有一个十分普遍但又无法从统计上证伪的信念，是她们想要反对的，那就是拥有枪支会让人们感到更安全）。不过，在这里，她们遇到了她们自己提出来的问题。向人们提供准确的信息似乎无济于事，人们只会曲解这些信息。诉诸于人们的情感也许更有效，但这么做又与传播科学知识的目标背道而驰。在书的结尾，她们写道：“我们所面临的挑战在于，如何改变人们的思维方式，这些思维方式导致了错误的科学信念。”

“The Enigma of Reason”、 “The Knowledge Illusion” 和“Denying to the Grave”，这三本书都写于去年11月的总统大选之前。然而，它们都预言了Kellyanne Conway式人物以及“另一种事实”（alternative facts）的出现（译注：Conway是特朗普的顾问，“alternative facts”是她为白宫发言人Spicer辩护时说出来的著名谎言）。这些日子，人们感觉好像整个国家都在进行一场巨大的心理实验，这场实验要么无人主导，要么主导者就是Steve Bannon（译注：特朗普的首席幕僚）。理性之士也许能够想出问题的解决办法，然而，在改变人们想法的问题上，即便文学故事也爱莫能助（译注：作者擅长通过讲故事而不是讲道理，让读者改变想法，为她赢得普利策奖的《大灭绝时代》就试图通过讲故事的方式改变人们对生态环保的看法）。

(XYS20170304)

