---
layout: default
Lastmod: 2020-07-14T08:27:07.572567+00:00
date: 2019-08-16T14:49:38.000Z
title: "这个互联网上最「脏」的工作，为什么无法消失？"
author: "https://www.ifanr.com/author/wuzhiqi"
tags: [审核员,8230,审核,违禁,平台]
---

在柏林不起眼的办公室里，600 名员工如冰冷的机器一般，目不转睛地盯着屏幕，拿着一个鼠标频频点击，却做着影响全球 20 亿人的事情：

> 网上每天超过一百种语言的数十亿帖子，哪些可以放出？哪些需要保留？哪些需要立刻删掉？

他们是 Facebook 的内容审核员们，几乎每 10 秒就要做出一个决定。

![](https://images.weserv.nl/?url=https%3A//s3.ifanr.com/wp-content/uploads/2019/08/15-2.png%21720)

▲Vice 实探 Facebook 的审核员工作环境. 图片来自：MAX HOPPENSTEDT

这个群体，大部分其实并不了解。他们不在深不可测的暗网，也并非和网民近在咫尺，但近月加州大学教授 Sarah T. Roberts 出了[一本新书《屏幕背后》](https://www.washingtonpost.com/technology/2019/07/25/social-media-companies-are-outsourcing-their-dirty-work-philippines-generation-workers-is-paying-price/?noredirect=on)讲到：

> 社交媒体上最阴暗的一面，不在广大网民的的屏幕里，而在内容审核员眼前。

### 1 天审 25000 条内容背后

> 你好，你发表的 \*\*\*，因为含有违反相关法律法规或管理规定的内容，已被移除。

当你发在微博、B 站、豆瓣上的内容无法通过审查或突然被删除时，就是内容审核员在工作了。

国内外各大互联网公司每年都在扩招该岗位，单 Facebook 在全球就已经有 20,000 多名审核员，这似乎是一个永远都在缺失中的职业。

![](https://images.weserv.nl/?url=https%3A//s3.ifanr.com/wp-content/uploads/2019/08/2-10.png%21720)

在早期，互联网还是一片分散的网络，连接数十亿个网站和社区的人们，随着互联网越来越「公司化」，Facebook，YouTube，Instagram……[内容审核员开始出现](https://motherboard.vice.com/en_us/article/vvbe5b/how-the-world-wide-web-became-the-internets-killer-app)，用来监管它们各自的网站。

所以简单来说，内容审核员就是将网上涉嫌违规的内容删掉的人。不过它带给人们的第一印象，一般都是「鉴黄师」。

![](https://images.weserv.nl/?url=https%3A//s3.ifanr.com/wp-content/uploads/2019/08/aa989719-1c57-4f5b-8170-41a4ebb9f58c.png%21720)

「鉴黄」没错，但只是工作内容的一部分，尽管很多人还认为这是一种额外福利，但它并没人们想象的那么简单。

在一部 [《网络清道夫》的纪录片](https://movie.douban.com/subject/27621580/)中，Facebook 的内容审核员一天的处理指标是 25000 个。而这些内容中遍地都是儿童色情、恐怖主义、自残虐杀、极端组织言论……. 他们的职责，是把最肮脏和恶心的信息阻隔在我们可以看到的世界之外。

![](https://images.weserv.nl/?url=https%3A//s3.ifanr.com/wp-content/uploads/2019/08/3-7.png%21720)

刺激、压抑、愤怒、冷漠、道德谴责…… 各种情绪混杂，不断刷新感官、挑战忍耐极限。但这不是过山车，翻腾后就能回到地面，每个新上岗的人一直得在车上，只能从原始的刺激慢慢变成习惯后的麻木。

> [要做这个工作，你必须成为一个坚强的人，并且非常了解自己。](https://www.washingtonpost.com/technology/2019/07/25/social-media-companies-are-outsourcing-their-dirty-work-philippines-generation-workers-is-paying-price/?noredirect=on)

![](https://images.weserv.nl/?url=https%3A//s3.ifanr.com/wp-content/uploads/2019/08/121.gif)

而据国内某互联网企业的员工叙述，他们的日常工作，除了会出现一些极端的情况，大部分时间可以说是反复甚至有些枯燥的：

> 单一的工作环境。 盯着屏幕一整天，白天黑夜紊乱。 从成千上万的自拍照、度假照、恶俗视频里，重点搜索涉黄和涉政，还有一小部分赌博、高利贷、卖枪卖药的帖子。
> 
> 删除，再看，再删除，再看。

![](https://images.weserv.nl/?url=https%3A//s3.ifanr.com/wp-content/uploads/2019/08/121212.png%21720)

▲虽然是著名的越战照片，但也会也因为「捍卫未成年人的裸照」而被删除

另外，他们的平均薪水仅高于最低工资。内容审核规则十分模糊，且经常变化，大部分靠既定模型和长期经验中把握尺度，但有时候看上头命令，有时候看上司命令。每个月都有人来，有人走，公司从来不留人。

只是一群普通人突然接触到了禁忌世界，因为频繁血腥而残酷的内容，导致压力也越来越大，累计到一定阈值就开始溃堤。

2017 年一桩 [Facebook 的集体诉讼案](https://www.vice.com/en_us/article/zm5mw5/facebook-content-moderation-lawsuit-ptsd)中，数千名内容审核员表示在工作中受到了严重的心理伤害，导致发生创伤后应激障碍，「睡眠中一点响动都会让我[有遭遇车祸的错觉](https://www.washingtonpost.com/technology/2019/07/25/social-media-companies-are-outsourcing-their-dirty-work-philippines-generation-workers-is-paying-price/?noredirect=on)」。

![](https://images.weserv.nl/?url=https%3A//s3.ifanr.com/wp-content/uploads/2019/08/getty.jpg%21720)

但这又是一份不可或缺，至关重要的工作：网络清道夫，就是互联网的安全卫士，如果他们不清理违禁内容，不阻挡那些非法信息，就会有更多青少年和小孩看到。

Google、Facebook 这些大公司非常重视它们，现在已经几乎让数十万人任职，虽然它们也为审核员提供了心理健康咨询和检查，[但](https://www.vice.com/en_us/article/xyezeq/theres-no-safe-way-to-keep-child-porn-and-murder-off-facebook)[也依然承认](https://www.vice.com/en_us/article/xyezeq/theres-no-safe-way-to-keep-child-porn-and-murder-off-facebook)，内容审核员是科技界最具心理创伤的工作之一。

![](https://images.weserv.nl/?url=https%3A//s3.ifanr.com/wp-content/uploads/2019/08/666-2.png%21720)

那这份「悲伤职业」，有没有可能用更好的方式去解决，甚至，人类可以不再做这类工作？

### 无法消失的内容审核员

事实上，目前的内容审核只能是人来进行的——猫捉老鼠的游戏。

但好的一面是，现在还有 AI 能帮他们预先灭掉「一窝蛇鼠」。

随着互联网公司审核员投诉和抗议事件屡发，再加上互联网用户上传内容量增加，头部平台每天产生的 UGC 内容量更是天文数字，人力投入昂贵且难以扩展，所以现在几乎所有公司，都已经在用「人+机器」的内容审核方式。

![](https://images.weserv.nl/?url=https%3A//s3.ifanr.com/wp-content/uploads/2019/08/11111-2.png%21720)

▲ 雅虎开源过一套深度学习神经网络，能给图片评估一个 NSFW（Not Suitable/Safe For Work）值，最无害的是 0，最极端是 1

国内最早利用 AI 技术从事内容审核服务的图普科技，据说现在对于色情、暴恐、低俗、诈骗等内容已经能达到 99% 的识别率，降低 90% 以上的人工审核成本。

在人机结合的审核里，首先 AI 会进行第一阶段海量内容的审核，区分正常内容、确定的不良内容以及不明确的内容，然后帖子被分类分配出来，再由审核员对「不明确的内容」进行人工复审。

这样一来，AI 能够帮内容审核员减轻负担，让他们更高效地去做决策，专注于数据分析。

![](https://images.weserv.nl/?url=https%3A//s3.ifanr.com/wp-content/uploads/2019/08/12121-1.png%21720)

但要让人工智能取代人力，现在依然像是天方夜谭。

虽然 AI 技术发展越来越快，但是因为自然语言处理（NLP）的难度，机器在理解语言上，还不能达到人类的思维程度，所以审核文字也会失误，更何况是图片、音频、视频。

深度学习的局限性在于，如果要创建准确检测[成人内容的神经网络](https://www.pcmag.com/news/369398/human-help-wanted-why-ai-is-terrible-at-content-moderation)，则必须先让 AI 在数百万个带注释的成人内容来训练。没有高质量的培训数据，AI 就很容易犯下错误。

![](https://images.weserv.nl/?url=https%3A//s3.ifanr.com/wp-content/uploads/2019/08/22-4.png%21720)

AI 擅长识别色情、垃圾邮件和虚假帐户，但因为审核量太大，类目很多，边界模糊，就像女性母乳喂养、月经艺术、战争暴行，也会被[误认为违禁内容](https://www.pcmag.com/news/369398/human-help-wanted-why-ai-is-terrible-at-content-moderation)，被 AI 识别挑选出的违禁图片里，还有数不尽的加菲猫，因为有它的画面里，几乎都是黄色。

毕竟机器是人「喂」出来的，所以机器目前主要还是协助工作，无法思考和判断有价值观的「违禁内容」。

比如仇恨言论和骚扰方面，它识别的准确率就很差，Facebook 认为它们可能需要 5 到 10 年的时间才能开发出可以发现仇恨言论的 AI。

![](https://images.weserv.nl/?url=https%3A//s3.ifanr.com/wp-content/uploads/2019/08/MICHELLE-THOMPSON.png%21720)

图普科技 CEO 李明强在接受爱范儿采访时也表示：

> 不得不承认的一个事实是，现阶段 AI 还处于弱人工智能阶段，只有将来 AI 具备自主学习、独立思考的能力，达到人类的理性和感性判断，也就是强人工智能阶段，那时才有取代人力的可能。
> 
> 因此，内容审核员在未来很长一段时间内都不会消失。

在这漫长的未来里，可以预见的是，随着信息传播量越来越大，图片视频样式不断翻新，AI 技术会不断升级，内容审核员也只会被继续要求审查更高标准的、具有细微差别的违禁内容。

![](https://images.weserv.nl/?url=https%3A//s3.ifanr.com/wp-content/uploads/2019/08/CONTENTBOT.NET_.png%21720)

只是未来，网络环境也不一定就会更「绿色健康」。

### 无法消失的网络黄暴恐

和内容审核员一样，黄暴恐可能也会一直在网上「存活」。

在这个比以往更容易自由表达的当下，人人发出自我的声音，但这份自由属于所有人，我们很难保证别人的自由不会伤害到我们自身，这是必然会产生的代价。

![](https://images.weserv.nl/?url=https%3A//s3.ifanr.com/wp-content/uploads/2019/08/SETH-LAUPUS.png%21720)

同时，随着互联网内容产业的竞争进入下半场，各家的流量之争也越发激烈。

每个平台的内容审核员，除了删除违禁内容，也会有意识地只放对平台有利的内容，从而打造出自己平台独特的品牌风格，这也是品牌保护的一种形式。

但所有平台共同的一点是：它们都需要靠用户的注意力存活下去。

### ![](https://images.weserv.nl/?url=https%3A//s3.ifanr.com/wp-content/uploads/2019/08/SHUTTERSTOCK-.png%21720)

为了让用户不断上瘾，这些公司就会通过越加精准的数据算法加上人工挑选，让人们在平台上停留更久时间，让人们越想看的越呈现，但：黄、暴、恐恰恰就是人性欲望之所在。

在一个又一个网络热点中，已经可以看出，人性本能就喜欢不断刷新底线的、挑战禁忌的、煽动对立的、制造愤怒的内容，恰恰社交平台却想要保持绿色健康美好光明的环境——这是个永远无法解决的矛盾。

![](https://images.weserv.nl/?url=https%3A//s3.ifanr.com/wp-content/uploads/2019/08/33-1.png%21720)

在这种冲突之下，各大平台似乎只能险中求稳。

对网民来说，尽管我们看到的内容，是被选择过的，或者被定制过的，而且它会让我们无法认识深层的丑恶真相，但更重要的是我们在任何情况下，都具有批判和思考的能力。

比起让无底线的霸凌、犯罪、羞辱、反动遍布全网，把灾难的火苗在源头掐灭，总归来说利大于弊。

内容审核员无法消失，「黄暴恐」也无法消失，我们只能让技术更加先进，让规则更加清晰，不然互联网可能会朝着无法回头的极端走去。

![](https://images.weserv.nl/?url=https%3A//s3.ifanr.com/wp-content/uploads/2019/08/TIN-VARSAVSKY-FLICKR.png%21720)

▲ 图片来自：TIN VARSAVSKY／FLICKR

但无论什么情况下，对我们而言最重要的，正如扎克伯格[在一次发布会上所说](https://www.sohu.com/a/136346376_680815)：

> 我们需要勇气去选择希望而非恐惧，去宣示我们能让世界变得更美好。我们必须保持乐观，正是这份希望和这份乐观促成了一个个伟大的进步。更重要的是，我们需要共同努力。

毕竟对比现实的深渊，内容审核员看到的残酷万象，也只是冰山一角。

